欢迎来到wow-rag的第一课。在本课中，wow这个词的含义不是令人惊叹，而是土的掉渣。

我们推荐用Jupyter Notebook来运行本教程的代码。可以先python -m venv myenv建立一个虚拟环境，然后激活这个虚拟环境。在虚拟环境中安装好Jupyter Notebook。
请自己新建一个空白的可用的ipynb文件并打开。

由于价格或者墙的原因，我们用着OpenAI的模型不是那么方便。不过openai的python库还是挺好用的，所以我们可以把openai的python库背后的模型换成国内的大模型。

### 安装依赖库
运行本代码之前，你需要安装一些额外的依赖。在Jupyter的格子中输入以下内容。

%pip install faiss-cpu scikit-learn scipy
%pip install openai

然后我们就可以用国内模型的api_key和base_url来创建一个client了。

国内模型可以是KIMI、智谱、Yi、deepseek等等。我们这里以智谱为例。

新建一个keys.txt文件，里面填入两行字符串：
第一个api_key
第二个api_key

### 构造对话模型接口
要想用openai库对接国内的大模型，只需要提供两个东西。第一是api_key，这个需要到各家的开放平台上去申请。第二就是base_url，一般是每家都有一个固定的地址，比如智谱的是https://open.bigmodel.cn/api/paas/v4/

```python
from openai import OpenAI
# 从文件导入所需要的secret keys
# keys.txt这文件要提前自己建好，本教程是使用第二行的这个key
with open('keys.txt', 'r', encoding='utf-8') as f:  
    keylist = f.read().split('\n')
client = OpenAI(
    api_key=keylist[1],
    base_url="https://open.bigmodel.cn/api/paas/v4/"
)
```

有了这个client，我们就可以去实现各种能力了。

### 构造文档
对文章进行切分后存入到数据库。我们选取了来自AGENT AI: SURVEYING THE HORIZONS OF MULTIMODAL INTERACTION的部分文章段落并进行嵌入。 由于文章太长，我们先要对文章进行切分。在这里，我们使用没有任何优化的顺序切分器，将文章分成了 150 个字符一段的小文本块。

```python
import numpy as np
import faiss

embedding_text = """
Multimodal Agent AI systems have many applications. In addition to interactive AI, grounded multimodal models could help drive content generation for bots and AI agents, and assist in productivity applications, helping to re-play, paraphrase, action prediction or synthesize 3D or 2D scenario. Fundamental advances in agent AI help contribute towards these goals and many would benefit from a greater understanding of how to model embodied and empathetic in a simulate reality or a real world. Arguably many of these applications could have positive benefits.

However, this technology could also be used by bad actors. Agent AI systems that generate content can be used to manipulate or deceive people. Therefore, it is very important that this technology is developed in accordance with responsible AI guidelines. For example, explicitly communicating to users that content is generated by an AI system and providing the user with controls in order to customize such a system. It is possible the Agent AI could be used to develop new methods to detect manipulative content - partly because it is rich with hallucination performance of large foundation model - and thus help address another real world problem.

For examples, 1) in health topic, ethical deployment of LLM and VLM agents, especially in sensitive domains like healthcare, is paramount. AI agents trained on biased data could potentially worsen health disparities by providing inaccurate diagnoses for underrepresented groups. Moreover, the handling of sensitive patient data by AI agents raises significant privacy and confidentiality concerns. 2) In the gaming industry, AI agents could transform the role of developers, shifting their focus from scripting non-player characters to refining agent learning processes. Similarly, adaptive robotic systems could redefine manufacturing roles, necessitating new skill sets rather than replacing human workers. Navigating these transitions responsibly is vital to minimize potential socio-economic disruptions.

Furthermore, the agent AI focuses on learning collaboration policy in simulation and there is some risk if directly applying the policy to the real world due to the distribution shift. Robust testing and continual safety monitoring mechanisms should be put in place to minimize risks of unpredictable behaviors in real-world scenarios. Our “VideoAnalytica" dataset is collected from the Internet and considering which is not a fully representative source, so we already go through-ed the ethical review and legal process from both Microsoft and University Washington. Be that as it may, we also need to understand biases that might exist in this corpus. Data distributions can be characterized in many ways. In this workshop, we have captured how the agent level distribution in our dataset is different from other existing datasets. However, there is much more than could be included in a single dataset or workshop. We would argue that there is a need for more approaches or discussion linked to real tasks or topics and that by making these data or system available.

We will dedicate a segment of our project to discussing these ethical issues, exploring potential mitigation strategies, and deploying a responsible multi-modal AI agent. We hope to help more researchers answer these questions together via this paper.

"""

chunk_size = 150
chunks = [embedding_text[i:i + chunk_size] for i in range(0, len(embedding_text), chunk_size)]
```

### 向量化
接着，我们将这些小文本块进行 Embedding，得到一个 1024 维的向量。然后，我们将这些向量存入到一个向量数据库中，以便后续进行检索。

```python
from sklearn.preprocessing import normalize
import numpy as np
import faiss

embeddings = []
for chunk in chunks:
    response = client.embeddings.create(
        model="embedding-2",
        input=chunk,
    )
    embeddings.append(response.data[0].embedding)
normalized_embeddings = normalize(np.array(embeddings).astype('float32'))
d = 1024
index = faiss.IndexFlatIP(d)
index.add(normalized_embeddings)

n_vectors = index.ntotal

print(n_vectors)
```
可以看到23块文本转化成了23个向量。

我们可以使用向量数据库进行检索。下面代码实现了一个名为match_text的函数，其目的是在一个文本集合中找到与给定输入文本最相似的文本块。
其中 k是要返回的相似文本块的数量。

```python
from sklearn.preprocessing import normalize
def match_text(input_text, index, chunks, k=2):
    k = min(k, len(chunks))

    response = client.embeddings.create(
        model="embedding-2",
        input=input_text,
    )
    input_embedding = response.data[0].embedding
    input_embedding = normalize(np.array([input_embedding]).astype('float32'))

    distances, indices = index.search(input_embedding, k)
    matching_texts = ""
    for i, idx in enumerate(indices[0]):
        print(f"similarity: {distances[0][i]:.4f}\nmatching text: \n{chunks[idx]}\n")
        matching_texts += f"similarity: {distances[0][i]:.4f}\nmatching text: \n{chunks[idx]}\n"

    return matching_texts
```

我们可以使用这个函数来检索一些文本。例如，我们可以检索一些与“Video Analytica dataset”最相似的文本块。

```python
input_text = "What are the applications of Agent AI systems ?"

matched_texts = match_text(input_text=input_text, index=index, chunks=chunks, k=2)
```

运行上面两行代码，将会得到如下输出：
similarity: 0.6645
matching text: 
ystem and providing the user with controls in order to customize such a system. It is possible the Agent AI could be used to develop new methods to de

similarity: 0.6368
matching text: 
r, the handling of sensitive patient data by AI agents raises significant privacy and confidentiality concerns. 2) In the gaming industry, AI agents c

similarity: 0.6362
matching text: 
mental advances in agent AI help contribute towards these goals and many would benefit from a greater understanding of how to model embodied and empat

### 构造提问prompt

```python
prompt = f"""
根据找到的文档
{matched_texts}
生成
{input_text}
的答案，尽可能使用文档语句的原文回答。不要复述问题，直接开始回答。
"""
```

### 构建对话引擎
```python
def get_completion_stream(prompt):
    response = client.chat.completions.create(
        model="glm-4-flash",  # 填写需要调用的模型名称
        messages=[
            {"role": "user", "content": prompt},
        ],
        stream=True,
    )
    if response:
        for chunk in response:
            content = chunk.choices[0].delta.content
            print(content, end='', flush=True)
```

接下来就可以去调用这个方法流式得到回答了

```python
get_completion_stream(prompt)
```

得到如下回答：

Agent AI systems can be utilized to develop new methods and contribute to various goals, such as providing users with customized controls within a system. Additionally, these systems can help advance mental capabilities, potentially benefiting from a greater understanding of how to model embodied and empathetic interactions.