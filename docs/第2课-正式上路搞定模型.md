干活之前我们先准备好必备模型。一个llm模型，和一个embedding模型。
Llama index的版本如下：

```python
llama-index-core                         0.10.15
llama-index-embeddings-openai            0.1.5
llama-index-llms-openai                  0.1.8
llama-index-readers-file                 0.1.4
llama-index-vector-stores-faiss          0.1.1
llamaindex-py-client                     0.1.19
```

如果是在jupyter notebook里运行，需要先用魔法命令安装这些库。
%pip install llama-index-core==0.10.15
%pip install llama-index-embeddings-openai==0.1.5
%pip install llama-index-llms-openai==0.1.8
%pip install llama-index-readers-file==0.1.4
%pip install llama-index-vector-stores-faiss==0.1.1
%pip install llamaindex-py-client==0.1.19


这里需要注意的是，llama-index-core这个库的版本不能高于0.10.15，llama-index-readers-file这个库的版本不能高于0.1.4，新版本会引入nltk依赖，然后会下载一个语言包，速度超慢。

我们想要借助llama_index的OpenAI接口使用智谱的模型，通过翻阅源码，发现llama index 把OpenAI和OpenAIEmbedding的模型名称写死在代码里了。所以需要修改源码，把智谱的模型名称添加进入，就可以了
假如说我们想要添加进智谱的glm-4-flash和embedding-2模型，实际上其他智谱模型也是同理。

### 修改对话模型源码
找到这个文件：Lib\site-packages\llama_index\llms\openai\utils.py

在大约第30行，有一个GPT4_MODELS: Dict[str, int]
在这里面列举了很多模型的名称，把智谱的glm-4-flash加进入，变成这样：

"gpt-4": 8192,
"gpt-4-32k": 32768,

改成：

"gpt-4": 8192,
"glm-4-flash": 8192,
"gpt-4-32k": 32768,




### 修改嵌入模型源码

改源码：
Lib\site-packages\llama_index\embeddings\openai\base.py

一共改四个地方

class OpenAIEmbeddingModelType(str, Enum):
最下面增加 
EMBED_2 = "embedding-2"

class OpenAIEmbeddingModeModel(str, Enum):
最下面增加 
EMBED_2 = "embedding-2"

_QUERY_MODE_MODEL_DICT = {
最下面增加 
(OAEM.TEXT_SEARCH_MODE, "embedding-2"): OAEMM.EMBED_2,
    
_TEXT_MODE_MODEL_DICT = {
最下面增加 
(OAEM.TEXT_SEARCH_MODE, "embedding-2"): OAEMM.EMBED_2,

改了上面这四个地方，再调用OpenAIEmbedding这个类，就可以正常使用了
如果怕麻烦，也可以用教程里附的base.py 直接替换。

如果不小心导入过llama_index，改完源码不要忘了重启jupyter内核。

### 运行对话模型
```python
# 从文件导入所需要的secret keys
with open('keys.txt', 'r', encoding='utf-8') as f:  
    keylist = f.read().split('\n')
from llama_index.llms.openai import OpenAI
llm = OpenAI(
    temperature=0.95,
    model="glm-4-flash",
    api_key=keylist[1],
    api_base="https://open.bigmodel.cn/api/paas/v4/"
)

# 测试对话模型
response = llm.complete("你是谁？")
print(response)
```


### 运行嵌入模型
```python
# 配置Embedding模型
from llama_index.embeddings.openai import OpenAIEmbedding
embedding = OpenAIEmbedding(
    model="embedding-2",
    api_key=keylist[1],
    api_base="https://open.bigmodel.cn/api/paas/v4/"
)

emb = embedding.get_text_embedding("你好呀呀")
len(emb), type(emb)
```
输出 (1024, list)

说明配置成功。

