{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package           Version\n",
      "----------------- -----------\n",
      "asttokens         2.4.1\n",
      "colorama          0.4.6\n",
      "comm              0.2.2\n",
      "debugpy           1.8.8\n",
      "decorator         5.1.1\n",
      "exceptiongroup    1.2.2\n",
      "executing         2.1.0\n",
      "ipykernel         6.29.5\n",
      "ipython           8.29.0\n",
      "jedi              0.19.2\n",
      "jupyter_client    8.6.3\n",
      "jupyter_core      5.7.2\n",
      "matplotlib-inline 0.1.7\n",
      "nest-asyncio      1.6.0\n",
      "packaging         24.2\n",
      "parso             0.8.4\n",
      "pip               22.0.4\n",
      "platformdirs      4.3.6\n",
      "prompt_toolkit    3.0.48\n",
      "psutil            6.1.0\n",
      "pure_eval         0.2.3\n",
      "Pygments          2.18.0\n",
      "python-dateutil   2.9.0.post0\n",
      "pywin32           308\n",
      "pyzmq             26.2.0\n",
      "setuptools        58.1.0\n",
      "six               1.16.0\n",
      "stack-data        0.6.3\n",
      "tornado           6.4.1\n",
      "traitlets         5.14.3\n",
      "typing_extensions 4.12.2\n",
      "wcwidth           0.2.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'E:\\NLP\\Python\\try-rag\\rag\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting faiss-cpu\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/10/3a/4b00c7076581795d8337e51dc65d1a1271b04f07c14b3de01cd32bb9ee96/faiss_cpu-1.9.0-cp310-cp310-win_amd64.whl (14.9 MB)\n",
      "     --------------------------------------- 14.9/14.9 MB 21.8 MB/s eta 0:00:00\n",
      "Collecting scikit-learn\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/48/76/154ebda6794faf0b0f3ccb1b5cd9a19f0a63cb9e1f3d2c61b6114002677b/scikit_learn-1.5.2-cp310-cp310-win_amd64.whl (11.0 MB)\n",
      "     --------------------------------------- 11.0/11.0 MB 22.6 MB/s eta 0:00:00\n",
      "Collecting scipy\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e7/1c/8daa6df17a945cb1a2a1e3bae3c49643f7b3b94017ff01a4787064f03f84/scipy-1.14.1-cp310-cp310-win_amd64.whl (44.8 MB)\n",
      "     --------------------------------------- 44.8/44.8 MB 17.7 MB/s eta 0:00:00\n",
      "Collecting numpy<3.0,>=1.25.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8e/8b/1c131ab5a94c1086c289c6e1da1d843de9dbd95fe5f5ee6e61904c9518e2/numpy-2.1.3-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "     --------------------------------------- 12.9/12.9 MB 17.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from faiss-cpu) (24.2)\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/4b/2c/ffbf7a134b9ab11a67b0cf0726453cedd9c5043a4fe7a35d1cefa9a1bcfb/threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting joblib>=1.2.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: threadpoolctl, numpy, joblib, scipy, faiss-cpu, scikit-learn\n",
      "Successfully installed faiss-cpu-1.9.0 joblib-1.4.2 numpy-2.1.3 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu scikit-learn scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting openai\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/30/90/7f6621a79de8b32f120e9790441c24dd9afafb2f1ca41fd3b9f4faaf8f9f/openai-1.54.5-py3-none-any.whl (389 kB)\n",
      "     -------------------------------------- 389.5/389.5 KB 1.9 MB/s eta 0:00:00\n",
      "Collecting anyio<5,>=3.5.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e4/f5/f2b75d2fc6f1a260f340f0e7c6a060f4dd2961cc16884ed851b0d18da06a/anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "     ---------------------------------------- 90.4/90.4 KB 1.0 MB/s eta 0:00:00\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/56/95/9377bcb415797e44274b51d46e3249eba641711cf3348050f76ee7b15ffc/httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "     ---------------------------------------- 76.4/76.4 KB 4.1 MB/s eta 0:00:00\n",
      "Collecting jiter<1,>=0.4.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b6/1b/79d038a632e2d00657ca4965b6f93454eb0e563ad9168f40050f320e5460/jiter-0.7.1-cp310-none-win_amd64.whl (201 kB)\n",
      "     -------------------------------------- 201.7/201.7 KB 3.0 MB/s eta 0:00:00\n",
      "Collecting sniffio\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Collecting pydantic<3,>=1.9.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/df/e4/ba44652d562cbf0bf320e0f3810206149c8a4e99cdbf66da82e97ab53a15/pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "     -------------------------------------- 434.9/434.9 KB 6.8 MB/s eta 0:00:00\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from openai) (4.12.2)\n",
      "Collecting tqdm>4\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/2b/78/57043611a16c655c8350b4c01b8d6abfb38cc2acb475238b62c2146186d7/tqdm-4.67.0-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.6/78.6 KB 4.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Collecting idna>=2.8\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/76/c6/c88e154df9c4e1a2a66ccf0005a88dfb2650c1dffb6f5ce603dfbd452ce3/idna-3.10-py3-none-any.whl (70 kB)\n",
      "     ---------------------------------------- 70.4/70.4 KB 4.0 MB/s eta 0:00:00\n",
      "Collecting certifi\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/12/90/3c9ff0512038035f59d279fddeb79f5f1eccd8859f06d6163c58798b9487/certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "     -------------------------------------- 167.3/167.3 KB 9.8 MB/s eta 0:00:00\n",
      "Collecting httpcore==1.*\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/87/f5/72347bc88306acb359581ac4d52f23c0ef445b57157adedb9aee0cd689d2/httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "     ---------------------------------------- 78.6/78.6 KB 4.3 MB/s eta 0:00:00\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.23.4\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/de/81/7dfe464eca78d76d31dd661b04b5f2036ec72ea8848dd87ab7375e185c23/pydantic_core-2.23.4-cp310-none-win_amd64.whl (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 20.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Installing collected packages: tqdm, sniffio, pydantic-core, jiter, idna, h11, distro, certifi, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.6.2.post1 certifi-2024.8.30 distro-1.9.0 h11-0.14.0 httpcore-1.0.7 httpx-0.27.2 idna-3.10 jiter-0.7.1 openai-1.54.5 pydantic-2.9.2 pydantic-core-2.23.4 sniffio-1.3.1 tqdm-4.67.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "# 从文件导入所需要的secret keys\n",
    "# keys.txt这文件要提前自己建好，本教程是使用第二行的这个key\n",
    "with open('keys.txt', 'r', encoding='utf-8') as f:  \n",
    "    keylist = f.read().split('\\n')\n",
    "client = OpenAI(\n",
    "    api_key=keylist[1],\n",
    "    base_url=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "embedding_text = \"\"\"\n",
    "Multimodal Agent AI systems have many applications. In addition to interactive AI, grounded multimodal models could help drive content generation for bots and AI agents, and assist in productivity applications, helping to re-play, paraphrase, action prediction or synthesize 3D or 2D scenario. Fundamental advances in agent AI help contribute towards these goals and many would benefit from a greater understanding of how to model embodied and empathetic in a simulate reality or a real world. Arguably many of these applications could have positive benefits.\n",
    "\n",
    "However, this technology could also be used by bad actors. Agent AI systems that generate content can be used to manipulate or deceive people. Therefore, it is very important that this technology is developed in accordance with responsible AI guidelines. For example, explicitly communicating to users that content is generated by an AI system and providing the user with controls in order to customize such a system. It is possible the Agent AI could be used to develop new methods to detect manipulative content - partly because it is rich with hallucination performance of large foundation model - and thus help address another real world problem.\n",
    "\n",
    "For examples, 1) in health topic, ethical deployment of LLM and VLM agents, especially in sensitive domains like healthcare, is paramount. AI agents trained on biased data could potentially worsen health disparities by providing inaccurate diagnoses for underrepresented groups. Moreover, the handling of sensitive patient data by AI agents raises significant privacy and confidentiality concerns. 2) In the gaming industry, AI agents could transform the role of developers, shifting their focus from scripting non-player characters to refining agent learning processes. Similarly, adaptive robotic systems could redefine manufacturing roles, necessitating new skill sets rather than replacing human workers. Navigating these transitions responsibly is vital to minimize potential socio-economic disruptions.\n",
    "\n",
    "Furthermore, the agent AI focuses on learning collaboration policy in simulation and there is some risk if directly applying the policy to the real world due to the distribution shift. Robust testing and continual safety monitoring mechanisms should be put in place to minimize risks of unpredictable behaviors in real-world scenarios. Our “VideoAnalytica\" dataset is collected from the Internet and considering which is not a fully representative source, so we already go through-ed the ethical review and legal process from both Microsoft and University Washington. Be that as it may, we also need to understand biases that might exist in this corpus. Data distributions can be characterized in many ways. In this workshop, we have captured how the agent level distribution in our dataset is different from other existing datasets. However, there is much more than could be included in a single dataset or workshop. We would argue that there is a need for more approaches or discussion linked to real tasks or topics and that by making these data or system available.\n",
    "\n",
    "We will dedicate a segment of our project to discussing these ethical issues, exploring potential mitigation strategies, and deploying a responsible multi-modal AI agent. We hope to help more researchers answer these questions together via this paper.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "chunk_size = 150\n",
    "chunks = [embedding_text[i:i + chunk_size] for i in range(0, len(embedding_text), chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "embeddings = []\n",
    "for chunk in chunks:\n",
    "    response = client.embeddings.create(\n",
    "        model=\"embedding-2\",\n",
    "        input=chunk,\n",
    "    )\n",
    "    embeddings.append(response.data[0].embedding)\n",
    "normalized_embeddings = normalize(np.array(embeddings).astype('float32'))\n",
    "d = 1024\n",
    "index = faiss.IndexFlatIP(d)\n",
    "index.add(normalized_embeddings)\n",
    "\n",
    "n_vectors = index.ntotal\n",
    "\n",
    "print(n_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "def match_text(input_text, index, chunks, k=2):\n",
    "    k = min(k, len(chunks))\n",
    "\n",
    "    response = client.embeddings.create(\n",
    "        model=\"embedding-2\",\n",
    "        input=input_text,\n",
    "    )\n",
    "    input_embedding = response.data[0].embedding\n",
    "    input_embedding = normalize(np.array([input_embedding]).astype('float32'))\n",
    "\n",
    "    distances, indices = index.search(input_embedding, k)\n",
    "    matching_texts = \"\"\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        print(f\"similarity: {distances[0][i]:.4f}\\nmatching text: \\n{chunks[idx]}\\n\")\n",
    "        matching_texts += f\"similarity: {distances[0][i]:.4f}\\nmatching text: \\n{chunks[idx]}\\n\"\n",
    "\n",
    "    return matching_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity: 0.7497\n",
      "matching text: \n",
      "ystem and providing the user with controls in order to customize such a system. It is possible the Agent AI could be used to develop new methods to de\n",
      "\n",
      "similarity: 0.7120\n",
      "matching text: \n",
      "mental advances in agent AI help contribute towards these goals and many would benefit from a greater understanding of how to model embodied and empat\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = \"What are the applications of Agent AI systems ?\"\n",
    "\n",
    "matched_texts = match_text(input_text=input_text, index=index, chunks=chunks, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'similarity: 0.7497\\nmatching text: \\nystem and providing the user with controls in order to customize such a system. It is possible the Agent AI could be used to develop new methods to de\\nsimilarity: 0.7120\\nmatching text: \\nmental advances in agent AI help contribute towards these goals and many would benefit from a greater understanding of how to model embodied and empat\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "根据找到的文档\n",
    "{matched_texts}\n",
    "生成\n",
    "{input_text}\n",
    "的答案，尽可能使用文档语句的原文回答。不要复述问题，直接开始回答。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_stream(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"glm-4-flash\",  # 填写需要调用的模型名称\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        stream=True,\n",
    "    )\n",
    "    if response:\n",
    "        for chunk in response:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            print(content, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent AI systems can be utilized to develop new methods and contribute to various goals, such as providing users with customized controls within a system. Additionally, these systems can help advance mental capabilities, potentially benefiting from a greater understanding of how to model embodied and empathetic interactions."
     ]
    }
   ],
   "source": [
    "\n",
    "get_completion_stream(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simpleNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting llama-index-core==0.10.15\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/53/2b/3b2f0d095df7287c63d3f72cdf0f942e0ae95984b91b1b57530f57b6d10e/llama_index_core-0.10.15-py3-none-any.whl (15.3 MB)\n",
      "     --------------------------------------- 15.3/15.3 MB 21.1 MB/s eta 0:00:00\n",
      "Collecting tenacity<9.0.0,>=8.2.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d2/3f/8ba87d9e287b9d385a02a7114ddcef61b26f86411e121c9003eb509a1773/tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core==0.10.15) (1.6.0)\n",
      "Collecting aiohttp<4.0.0,>=3.8.6\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/42/ce/7c3f297b18ff2c7955326f00cf7ed3cecfedd8cad086e2977bbb7aef8879/aiohttp-3.11.4-cp310-cp310-win_amd64.whl (440 kB)\n",
      "     ------------------------------------- 440.5/440.5 KB 13.9 MB/s eta 0:00:00\n",
      "Collecting dataclasses-json\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c3/be/d0d44e092656fe7a06b55e6103cbce807cdbdee17884a5367c68c9860853/dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core==0.10.15) (4.67.0)\n",
      "Requirement already satisfied: httpx in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core==0.10.15) (0.27.2)\n",
      "Collecting requests>=2.31.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/f9/9b/335f9764261e915ed497fcdeb11df5dfd6f7bf257d4a6a2a686d80da4d54/requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Collecting deprecated>=1.2.9.3\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/1d/8f/c7f227eb42cfeaddce3eb0c96c60cbca37797fa7b34f8e1aeadf6c5c0983/Deprecated-1.2.15-py2.py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core==0.10.15) (4.12.2)\n",
      "Collecting typing-inspect>=0.8.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting tiktoken>=0.3.3\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/dc/da/8d1cc3089a83f5cf11c2e489332752981435280285231924557350523a59/tiktoken-0.8.0-cp310-cp310-win_amd64.whl (884 kB)\n",
      "     ------------------------------------- 884.2/884.2 KB 28.2 MB/s eta 0:00:00\n",
      "Collecting pillow>=9.0.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d5/4e/78f7c5202ea2a772a5ab05069c1b82503e6353cd79c7e474d4945f4b82c3/pillow-11.0.0-cp310-cp310-win_amd64.whl (2.6 MB)\n",
      "     ---------------------------------------- 2.6/2.6 MB 16.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: openai>=1.1.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core==0.10.15) (1.54.5)\n",
      "Collecting pandas\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/31/9e/6ebb433de864a6cd45716af52a4d7a8c3c9aaf3a98368e61db9e69e69a9c/pandas-2.2.3-cp310-cp310-win_amd64.whl (11.6 MB)\n",
      "     --------------------------------------- 11.6/11.6 MB 24.3 MB/s eta 0:00:00\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c6/b2/454d6e7f0158951d8a78c2e1eb4f69ae81beb8dca5fee9809c6c99e9d0d0/fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "     ------------------------------------- 179.6/179.6 KB 10.6 MB/s eta 0:00:00\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/68/69/1bcf70f81de1b4a9f21b3a62ec0c83bdff991c88d6cc2267d02408457e88/dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Collecting PyYAML>=6.0.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b5/84/0fa4b06f6d6c958d207620fc60005e241ecedceee58931bb20138e1e5776/PyYAML-6.0.2-cp310-cp310-win_amd64.whl (161 kB)\n",
      "     ---------------------------------------- 161.8/161.8 KB ? eta 0:00:00\n",
      "Requirement already satisfied: numpy in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core==0.10.15) (2.1.3)\n",
      "Collecting llamaindex-py-client<0.2.0,>=0.1.13\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/5e/9c/a1a3086f023a8957ebd527c98d9356b6dd9409edef827ffdeee484f47abf/llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n",
      "     ---------------------------------------- 141.9/141.9 KB ? eta 0:00:00\n",
      "Collecting nltk<4.0.0,>=3.8.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/4d/66/7d9e26593edda06e8cb531874633f7c2372279c3b0f46235539fe546df8b/nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 24.1 MB/s eta 0:00:00\n",
      "Collecting SQLAlchemy[asyncio]>=1.4.49\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/aa/af/ad9c25cadc79bd851bdb9d82b68af9bdb91ff05f56d0da2f8a654825974f/SQLAlchemy-2.0.36-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 26.7 MB/s eta 0:00:00\n",
      "Collecting networkx>=3.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/b9/54/dd730b32ea14ea797530a4479b2ed46a6fb250f682a9cfb997e968bf0261/networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 18.2 MB/s eta 0:00:00\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/6a/21/5b6702a7f963e95456c0de2d495f67bf5fd62840ac655dc451586d23d39a/attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/4c/ec/a4bf3e3adfc62a72af70475e2126c71f693c05321bfd38661dc98ecb270f/yarl-1.17.2-cp310-cp310-win_amd64.whl (89 kB)\n",
      "     ---------------------------------------- 90.0/90.0 KB 5.0 MB/s eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/28/2f/cc27d5f43e023d21fe5c19538e08894db3d7e081cbf582ad5ed366c24446/frozenlist-1.5.0-cp310-cp310-win_amd64.whl (51 kB)\n",
      "     -------------------------------------- 51.6/51.6 KB 221.3 kB/s eta 0:00:00\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/04/5a/d88cd5d00a184e1ddffc82aa2e6e915164a6d2641ed3606e766b5d2f275a/multidict-6.1.0-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Collecting async-timeout<6.0,>=4.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/fe/ba/e2081de779ca30d473f21f5b30e0e737c438205440784c7dfc81efc2b029/async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f7/d8/120cd0fe3e8530df0539e71ba9683eade12cae103dd7543e50d15f737917/aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/bb/44/6c2add5eeafb7f31ff0d25fbc005d930bea040a1364cf0f5768750ddf4d1/propcache-0.2.0-cp310-cp310-win_amd64.whl (44 kB)\n",
      "     -------------------------------------- 45.0/45.0 KB 738.7 kB/s eta 0:00:00\n",
      "Collecting wrapt<2,>=1.10\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/19/2b/548d23362e3002ebbfaefe649b833fa43f6ca37ac3e95472130c4b69e0b4/wrapt-1.16.0-cp310-cp310-win_amd64.whl (37 kB)\n",
      "Requirement already satisfied: pydantic>=1.10 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core==0.10.15) (2.9.2)\n",
      "Requirement already satisfied: idna in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core==0.10.15) (3.10)\n",
      "Requirement already satisfied: sniffio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core==0.10.15) (1.3.1)\n",
      "Requirement already satisfied: certifi in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core==0.10.15) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core==0.10.15) (1.0.7)\n",
      "Requirement already satisfied: anyio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core==0.10.15) (4.6.2.post1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core==0.10.15) (0.14.0)\n",
      "Collecting regex>=2021.8.3\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/42/7e/5f1b92c8468290c465fd50c5318da64319133231415a8aa6ea5ab995a815/regex-2024.11.6-cp310-cp310-win_amd64.whl (274 kB)\n",
      "     ------------------------------------- 274.0/274.0 KB 16.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core==0.10.15) (1.4.2)\n",
      "Collecting click\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from openai>=1.1.0->llama-index-core==0.10.15) (0.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from openai>=1.1.0->llama-index-core==0.10.15) (1.9.0)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d6/20/f1d4670a8a723c46be695dff449d86d6092916f9e99c53051954ee33a1bc/charset_normalizer-3.4.0-cp310-cp310-win_amd64.whl (102 kB)\n",
      "     -------------------------------------- 102.2/102.2 KB 1.5 MB/s eta 0:00:00\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ce/d9/5f4c13cecde62396b0d3fe530a50ccea91e7dfc1ccf0e09c228841bb5ba8/urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "     ------------------------------------ 126.3/126.3 KB 744.2 kB/s eta 0:00:00\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/96/28/d62835fb33fb5652f2e98d34c44ad1a0feacc8b1d3f1aecab035f51f267d/greenlet-3.1.1-cp310-cp310-win_amd64.whl (298 kB)\n",
      "     ------------------------------------- 298.4/298.4 KB 18.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core==0.10.15) (0.4.6)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/2a/e2/5d3f6ada4297caebe1a2add3b126fe800c96f56dbe5d1988a2cbe0b267aa/mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ac/a7/a78ff54e67ef92a3d12126b98eb98ab8abab3de4a8c46d240c87e514d6bb/marshmallow-3.23.1-py3-none-any.whl (49 kB)\n",
      "     ---------------------------------------- 49.5/49.5 KB 2.6 MB/s eta 0:00:00\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a6/ab/7e5f53c3b9d14972843a647d8d7a853969a58aecc7559cb3267302c94774/tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "     ------------------------------------- 346.6/346.6 KB 21.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pandas->llama-index-core==0.10.15) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/11/c3/005fcca25ce078d2cc29fd559379817424e94885510568bc1bc53d7d5846/pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "     ------------------------------------- 508.0/508.0 KB 16.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from anyio->httpx->llama-index-core==0.10.15) (1.2.2)\n",
      "Requirement already satisfied: packaging>=17.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.10.15) (24.2)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core==0.10.15) (2.23.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core==0.10.15) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core==0.10.15) (1.16.0)\n",
      "Installing collected packages: pytz, dirtyjson, wrapt, urllib3, tzdata, tenacity, regex, PyYAML, propcache, pillow, networkx, mypy-extensions, multidict, marshmallow, greenlet, fsspec, frozenlist, click, charset-normalizer, attrs, async-timeout, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, requests, pandas, nltk, deprecated, aiosignal, tiktoken, llamaindex-py-client, dataclasses-json, aiohttp, llama-index-core\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.3 aiohttp-3.11.4 aiosignal-1.3.1 async-timeout-5.0.1 attrs-24.2.0 charset-normalizer-3.4.0 click-8.1.7 dataclasses-json-0.6.7 deprecated-1.2.15 dirtyjson-1.0.8 frozenlist-1.5.0 fsspec-2024.10.0 greenlet-3.1.1 llama-index-core-0.10.15 llamaindex-py-client-0.1.19 marshmallow-3.23.1 multidict-6.1.0 mypy-extensions-1.0.0 networkx-3.4.2 nltk-3.9.1 pandas-2.2.3 pillow-11.0.0 propcache-0.2.0 pytz-2024.2 regex-2024.11.6 requests-2.32.3 tenacity-8.5.0 tiktoken-0.8.0 typing-inspect-0.9.0 tzdata-2024.2 urllib3-2.2.3 wrapt-1.16.0 yarl-1.17.2\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting llama-index-embeddings-openai==0.1.5\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/7d/b8/e727b40b95b762f8e35bb65f518ae92f0a8b591b6088452fdb70e3442211/llama_index_embeddings_openai-0.1.5-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-embeddings-openai==0.1.5) (0.10.15)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (1.6.0)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (1.2.15)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (0.1.19)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (4.12.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (11.0.0)\n",
      "Requirement already satisfied: networkx>=3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (3.4.2)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (6.0.2)\n",
      "Requirement already satisfied: dataclasses-json in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (0.6.7)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (0.8.0)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (3.9.1)\n",
      "Requirement already satisfied: openai>=1.1.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (1.54.5)\n",
      "Requirement already satisfied: requests>=2.31.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (2.32.3)\n",
      "Requirement already satisfied: pandas in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (2.2.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (8.5.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (0.9.0)\n",
      "Requirement already satisfied: numpy in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (2.1.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (3.11.4)\n",
      "Requirement already satisfied: httpx in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (0.27.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (4.67.0)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (2.0.36)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (2024.10.0)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (1.0.8)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (2.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (0.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (6.1.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (1.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (24.2.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (1.16.0)\n",
      "Requirement already satisfied: pydantic>=1.10 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (2.9.2)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (1.0.7)\n",
      "Requirement already satisfied: idna in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (3.10)\n",
      "Requirement already satisfied: certifi in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (2024.8.30)\n",
      "Requirement already satisfied: anyio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (4.6.2.post1)\n",
      "Requirement already satisfied: sniffio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (0.14.0)\n",
      "Requirement already satisfied: click in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (8.1.7)\n",
      "Requirement already satisfied: joblib in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (2024.11.6)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (0.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (3.1.1)\n",
      "Requirement already satisfied: colorama in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (3.23.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (2.9.0.post0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (1.2.2)\n",
      "Requirement already satisfied: packaging>=17.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (24.2)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (2.23.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai==0.1.5) (1.16.0)\n",
      "Installing collected packages: llama-index-embeddings-openai\n",
      "Successfully installed llama-index-embeddings-openai-0.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simpleNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting llama-index-llms-openai==0.1.8\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/e1/b7/5d809fd28deb3eb9add3c54e5077f016df61494ee86492d236d3d5fdf261/llama_index_llms_openai-0.1.8-py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-llms-openai==0.1.8) (0.10.15)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (6.0.2)\n",
      "Requirement already satisfied: pillow>=9.0.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (11.0.0)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (1.2.15)\n",
      "Requirement already satisfied: networkx>=3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (3.4.2)\n",
      "Requirement already satisfied: httpx in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (0.27.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (2024.10.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (2.32.3)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (0.1.19)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (0.8.0)\n",
      "Requirement already satisfied: dataclasses-json in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (0.6.7)\n",
      "Requirement already satisfied: numpy in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (2.1.3)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (1.0.8)\n",
      "Requirement already satisfied: openai>=1.1.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (1.54.5)\n",
      "Requirement already satisfied: pandas in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (2.2.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (8.5.0)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (2.0.36)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (1.6.0)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (3.9.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (0.9.0)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (3.11.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (1.3.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (0.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (6.1.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (2.4.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (1.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (24.2.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (5.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (1.17.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (1.16.0)\n",
      "Requirement already satisfied: pydantic>=1.10 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (2.9.2)\n",
      "Requirement already satisfied: certifi in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (2024.8.30)\n",
      "Requirement already satisfied: idna in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (3.10)\n",
      "Requirement already satisfied: anyio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (4.6.2.post1)\n",
      "Requirement already satisfied: sniffio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (0.14.0)\n",
      "Requirement already satisfied: click in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (2024.11.6)\n",
      "Requirement already satisfied: joblib in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (1.4.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (0.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (3.1.1)\n",
      "Requirement already satisfied: colorama in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (3.23.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (2024.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (1.2.2)\n",
      "Requirement already satisfied: packaging>=17.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (24.2)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (2.23.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-openai==0.1.8) (1.16.0)\n",
      "Installing collected packages: llama-index-llms-openai\n",
      "Successfully installed llama-index-llms-openai-0.1.8\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting llama-index-readers-file==0.1.4\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/da/f3/685de42fefc0ed251b7aefde3a42983da53089f8430f6af3b34358f40c29/llama_index_readers_file-0.1.4-py3-none-any.whl (36 kB)\n",
      "Collecting bs4<0.0.3,>=0.0.2\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/51/bb/bf7aab772a159614954d84aa832c129624ba6c32faa559dfb200a534e50b/bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Collecting pypdf<5.0.0,>=4.0.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/3c/60/eccdd92dd4af3e4bea6d6a342f7588c618a15b9bec4b968af581e498bcc4/pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "     ------------------------------------ 295.8/295.8 KB 961.6 kB/s eta 0:00:00\n",
      "Collecting pymupdf<2.0.0,>=1.23.21\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/25/b2/82d70d9f5aea5a33e770f37e6db43ed08b5dc71b3526c5d7051689d1031e/PyMuPDF-1.24.14-cp39-abi3-win_amd64.whl (16.3 MB)\n",
      "     --------------------------------------- 16.3/16.3 MB 18.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-readers-file==0.1.4) (0.10.15)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3\n",
      "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/b1/fe/e8c672695b37eecc5cbf43e1d0638d88d66ba3a44c4d321c796f4e59167f/beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/d1/c2/fe97d779f3ef3b15f05c94a2f1e3d21732574ed441687474db9d342a7315/soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: openai>=1.1.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (1.54.5)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (3.9.1)\n",
      "Requirement already satisfied: requests>=2.31.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (2.32.3)\n",
      "Requirement already satisfied: httpx in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (0.27.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (8.5.0)\n",
      "Requirement already satisfied: pandas in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (2.2.3)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (3.11.4)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (0.9.0)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (1.2.15)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (1.6.0)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (1.0.8)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (0.8.0)\n",
      "Requirement already satisfied: numpy in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (2.1.3)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (0.1.19)\n",
      "Requirement already satisfied: dataclasses-json in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (0.6.7)\n",
      "Requirement already satisfied: networkx>=3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (3.4.2)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (6.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (4.67.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (2024.10.0)\n",
      "Requirement already satisfied: pillow>=9.0.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (11.0.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (24.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (0.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (1.17.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (5.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (1.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (2.4.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (1.16.0)\n",
      "Requirement already satisfied: pydantic>=1.10 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (2.9.2)\n",
      "Requirement already satisfied: certifi in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (2024.8.30)\n",
      "Requirement already satisfied: idna in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (3.10)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (1.0.7)\n",
      "Requirement already satisfied: sniffio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (1.3.1)\n",
      "Requirement already satisfied: anyio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (4.6.2.post1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (0.14.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (2024.11.6)\n",
      "Requirement already satisfied: joblib in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (1.4.2)\n",
      "Requirement already satisfied: click in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (8.1.7)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (0.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (3.1.1)\n",
      "Requirement already satisfied: colorama in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (3.23.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (2024.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (2.9.0.post0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (1.2.2)\n",
      "Requirement already satisfied: packaging>=17.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (24.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file==0.1.4) (1.16.0)\n",
      "Installing collected packages: soupsieve, pypdf, pymupdf, beautifulsoup4, bs4, llama-index-readers-file\n",
      "Successfully installed beautifulsoup4-4.12.3 bs4-0.0.2 llama-index-readers-file-0.1.4 pymupdf-1.24.14 pypdf-4.3.1 soupsieve-2.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting llama-index-vector-stores-faiss==0.1.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/64/f9/4f0c7aed47f14a484c98e12316d713cd393734207402f22eadb6befe5a1c/llama_index_vector_stores_faiss-0.1.1-py3-none-any.whl (3.8 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-vector-stores-faiss==0.1.1) (0.10.15)\n",
      "Requirement already satisfied: numpy in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (2.1.3)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (0.1.19)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (1.0.8)\n",
      "Requirement already satisfied: networkx>=3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (3.4.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (8.5.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (0.9.0)\n",
      "Requirement already satisfied: httpx in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (0.27.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (3.11.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (1.2.15)\n",
      "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (2.0.36)\n",
      "Requirement already satisfied: openai>=1.1.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (1.54.5)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (6.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (4.67.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (4.12.2)\n",
      "Requirement already satisfied: dataclasses-json in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (0.6.7)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (0.8.0)\n",
      "Requirement already satisfied: pandas in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (2.2.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (2024.10.0)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (1.6.0)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (3.9.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (11.0.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (1.17.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (0.2.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (1.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (2.4.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (24.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (1.3.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (1.16.0)\n",
      "Requirement already satisfied: pydantic>=1.10 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (2.9.2)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (1.0.7)\n",
      "Requirement already satisfied: anyio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (4.6.2.post1)\n",
      "Requirement already satisfied: sniffio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (1.3.1)\n",
      "Requirement already satisfied: idna in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (3.10)\n",
      "Requirement already satisfied: certifi in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (2024.8.30)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (0.14.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (2024.11.6)\n",
      "Requirement already satisfied: joblib in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (1.4.2)\n",
      "Requirement already satisfied: click in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (8.1.7)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (0.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (1.9.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (3.4.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (3.1.1)\n",
      "Requirement already satisfied: colorama in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from tqdm<5.0.0,>=4.66.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (3.23.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (2024.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (1.2.2)\n",
      "Requirement already satisfied: packaging>=17.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (24.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-faiss==0.1.1) (1.16.0)\n",
      "Installing collected packages: llama-index-vector-stores-faiss\n",
      "Successfully installed llama-index-vector-stores-faiss-0.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: llamaindex-py-client==0.1.19 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (0.1.19)\n",
      "Requirement already satisfied: pydantic>=1.10 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llamaindex-py-client==0.1.19) (2.9.2)\n",
      "Requirement already satisfied: httpx>=0.20.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from llamaindex-py-client==0.1.19) (0.27.2)\n",
      "Requirement already satisfied: certifi in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx>=0.20.0->llamaindex-py-client==0.1.19) (2024.8.30)\n",
      "Requirement already satisfied: idna in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx>=0.20.0->llamaindex-py-client==0.1.19) (3.10)\n",
      "Requirement already satisfied: sniffio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx>=0.20.0->llamaindex-py-client==0.1.19) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx>=0.20.0->llamaindex-py-client==0.1.19) (1.0.7)\n",
      "Requirement already satisfied: anyio in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpx>=0.20.0->llamaindex-py-client==0.1.19) (4.6.2.post1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from httpcore==1.*->httpx>=0.20.0->llamaindex-py-client==0.1.19) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client==0.1.19) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client==0.1.19) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic>=1.10->llamaindex-py-client==0.1.19) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from anyio->httpx>=0.20.0->llamaindex-py-client==0.1.19) (1.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install llama-index-core==0.10.15\n",
    "%pip install llama-index-embeddings-openai==0.1.5\n",
    "%pip install llama-index-llms-openai==0.1.8\n",
    "%pip install llama-index-readers-file==0.1.4\n",
    "%pip install llama-index-vector-stores-faiss==0.1.1\n",
    "%pip install llamaindex-py-client==0.1.19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个人工智能助手，名叫 ChatGLM，是基于清华大学 KEG 实验室和智谱 AI 公司于 2024 年共同训练的语言模型开发的。我的任务是针对用户的问题和要求提供适当的答复和支持。\n"
     ]
    }
   ],
   "source": [
    "# 从文件导入所需要的secret keys\n",
    "with open('keys.txt', 'r', encoding='utf-8') as f:  \n",
    "    keylist = f.read().split('\\n')\n",
    "from llama_index.llms.openai import OpenAI\n",
    "llm = OpenAI(\n",
    "    temperature=0.95,\n",
    "    model=\"glm-4-flash\",\n",
    "    api_key=keylist[1],\n",
    "    api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "\n",
    "# 测试对话模型\n",
    "response = llm.complete(\"你是谁？\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, list)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 配置Embedding模型\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "embedding = OpenAIEmbedding(\n",
    "    model=\"embedding-2\",\n",
    "    api_key=keylist[1],\n",
    "    api_base=\"https://open.bigmodel.cn/api/paas/v4/\"\n",
    ")\n",
    "\n",
    "emb = embedding.get_text_embedding(\"你好呀呀\")\n",
    "len(emb), type(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader,Document\n",
    "documents = SimpleDirectoryReader(input_files=['./docs/问答手册.txt']).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "index = VectorStoreIndex.from_documents(documents,embed_model=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_dir = \"./storage\"\n",
    "index.storage_context.persist(persist_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent AI systems can be applied in interactive AI, content generation for bots and AI agents, productivity applications like replaying, paraphrasing, action prediction, and synthesizing 3D or 2D scenarios. They can also contribute to health topic analysis, transform roles in the gaming industry by refining agent learning processes, redefine manufacturing roles through adaptive robotic systems, and assist in learning collaboration policies in simulation.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine(llm=llm)\n",
    "# 回答提问\n",
    "response = query_engine.query(\"What are the applications of Agent AI systems ?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "transformations = [SentenceSplitter(chunk_size = 512)]\n",
    "\n",
    "from llama_index.core.ingestion.pipeline import run_transformations\n",
    "nodes = run_transformations(documents, transformations=transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建索引\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "import faiss\n",
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "\n",
    "vector_store = FaissVectorStore(faiss_index=faiss.IndexFlatL2(1024))\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "index = VectorStoreIndex(\n",
    "    nodes = nodes,\n",
    "    storage_context=storage_context,\n",
    "    embed_model = embedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_dir = \"./storage\"\n",
    "index.storage_context.persist(persist_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load index from disk\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "import faiss\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "vector_store = FaissVectorStore.from_persist_dir(persist_dir)\n",
    "storage_context = StorageContext.from_defaults(\n",
    "    vector_store=vector_store, persist_dir=persist_dir\n",
    ")\n",
    "index = load_index_from_storage(storage_context=storage_context,embed_model = embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建检索器\n",
    "dimensions = len(emb)\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "# 想要自定义参数，可以构造参数字典\n",
    "kwargs = {'similarity_top_k': 5, 'index': index, 'dimensions': dimensions} # 必要参数\n",
    "retriever = VectorIndexRetriever(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.response_synthesizers  import get_response_synthesizer\n",
    "response_synthesizer = get_response_synthesizer(llm=llm)\n",
    "# 构建问答引擎\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "engine = RetrieverQueryEngine(\n",
    "      retriever=retriever,\n",
    "      response_synthesizer=response_synthesizer\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent AI systems can be applied in various domains such as content generation for bots and AI agents, productivity enhancement, replaying and paraphrasing content, action prediction, synthesizing 3D and 2D scenarios, health topic analysis, gaming industry transformation, and adaptive robotic systems in manufacturing. They can also contribute to learning collaboration policies in simulations.\n"
     ]
    }
   ],
   "source": [
    "# 提问\n",
    "question = \"What are the applications of Agent AI systems ?\"\n",
    "answer = engine.query(question)\n",
    "print(answer.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'061539ee-ff3b-4113-a766-f3039b697c62': TextNode(id_='061539ee-ff3b-4113-a766-f3039b697c62', embedding=None, metadata={'file_path': 'docs\\\\问答手册.txt', 'file_name': 'e:/NLP/Python/try-rag/docs/问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2024-11-19', 'last_modified_date': '2024-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='7e163de9-6172-497d-a1fd-dfbbb648b441', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'docs\\\\问答手册.txt', 'file_name': 'e:/NLP/Python/try-rag/docs/问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2024-11-19', 'last_modified_date': '2024-11-19'}, hash='a72c530c59da935d4a73b9d2e59a02d80f7618f736f9b52d75fbeab091523145'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='bd6460b9-e046-4ad5-8760-6c89a187eba7', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5128f538caf583931f5dcc7bd0d013dd356a78f5eaf21fb9dae1dba236603900')}, text='Multimodal Agent AI systems have many applications. In addition to interactive AI, grounded multimodal models could help drive content generation for bots and AI agents, and assist in productivity applications, helping to re-play, paraphrase, action prediction or synthesize 3D or 2D scenario. Fundamental advances in agent AI help contribute towards these goals and many would benefit from a greater understanding of how to model embodied and empathetic in a simulate reality or a real world. Arguably many of these applications could have positive benefits.\\r\\n\\r\\nHowever, this technology could also be used by bad actors. Agent AI systems that generate content can be used to manipulate or deceive people. Therefore, it is very important that this technology is developed in accordance with responsible AI guidelines. For example, explicitly communicating to users that content is generated by an AI system and providing the user with controls in order to customize such a system. It is possible the Agent AI could be used to develop new methods to detect manipulative content - partly because it is rich with hallucination performance of large foundation model - and thus help address another real world problem.\\r\\n\\r\\nFor examples, 1) in health topic, ethical deployment of LLM and VLM agents, especially in sensitive domains like healthcare, is paramount. AI agents trained on biased data could potentially worsen health disparities by providing inaccurate diagnoses for underrepresented groups. Moreover, the handling of sensitive patient data by AI agents raises significant privacy and confidentiality concerns. 2) In the gaming industry, AI agents could transform the role of developers, shifting their focus from scripting non-player characters to refining agent learning processes. Similarly, adaptive robotic systems could redefine manufacturing roles, necessitating new skill sets rather than replacing human workers. Navigating these transitions responsibly is vital to minimize potential socio-economic disruptions.\\r\\n\\r\\nFurthermore, the agent AI focuses on learning collaboration policy in simulation and there is some risk if directly applying the policy to the real world due to the distribution shift. Robust testing and continual safety monitoring mechanisms should be put in place to minimize risks of unpredictable behaviors in real-world scenarios. Our “VideoAnalytica\" dataset is collected from the Internet and considering which is not a fully representative source, so we already go through-ed the ethical review and legal process from both Microsoft and University Washington. Be that as it may, we also need to understand biases that might exist in this corpus. Data distributions can be characterized in many ways.', start_char_idx=0, end_char_idx=2736, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), 'bd6460b9-e046-4ad5-8760-6c89a187eba7': TextNode(id_='bd6460b9-e046-4ad5-8760-6c89a187eba7', embedding=None, metadata={'file_path': 'docs\\\\问答手册.txt', 'file_name': 'e:/NLP/Python/try-rag/docs/问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2024-11-19', 'last_modified_date': '2024-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='7e163de9-6172-497d-a1fd-dfbbb648b441', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'docs\\\\问答手册.txt', 'file_name': 'e:/NLP/Python/try-rag/docs/问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2024-11-19', 'last_modified_date': '2024-11-19'}, hash='a72c530c59da935d4a73b9d2e59a02d80f7618f736f9b52d75fbeab091523145'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='061539ee-ff3b-4113-a766-f3039b697c62', node_type=<ObjectType.TEXT: '1'>, metadata={'file_path': 'docs\\\\问答手册.txt', 'file_name': 'e:/NLP/Python/try-rag/docs/问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2024-11-19', 'last_modified_date': '2024-11-19'}, hash='9753ffda7b697335fd17f10798d641e4f23cd27b3013960ea0cd252c0b8d7a39')}, text='2) In the gaming industry, AI agents could transform the role of developers, shifting their focus from scripting non-player characters to refining agent learning processes. Similarly, adaptive robotic systems could redefine manufacturing roles, necessitating new skill sets rather than replacing human workers. Navigating these transitions responsibly is vital to minimize potential socio-economic disruptions.\\r\\n\\r\\nFurthermore, the agent AI focuses on learning collaboration policy in simulation and there is some risk if directly applying the policy to the real world due to the distribution shift. Robust testing and continual safety monitoring mechanisms should be put in place to minimize risks of unpredictable behaviors in real-world scenarios. Our “VideoAnalytica\" dataset is collected from the Internet and considering which is not a fully representative source, so we already go through-ed the ethical review and legal process from both Microsoft and University Washington. Be that as it may, we also need to understand biases that might exist in this corpus. Data distributions can be characterized in many ways. In this workshop, we have captured how the agent level distribution in our dataset is different from other existing datasets. However, there is much more than could be included in a single dataset or workshop. We would argue that there is a need for more approaches or discussion linked to real tasks or topics and that by making these data or system available.\\r\\n\\r\\nWe will dedicate a segment of our project to discussing these ethical issues, exploring potential mitigation strategies, and deploying a responsible multi-modal AI agent. We hope to help more researchers answer these questions together via this paper.', start_char_idx=1615, end_char_idx=3353, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')}\n"
     ]
    }
   ],
   "source": [
    "print(index.docstore.docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': '061539ee-ff3b-4113-a766-f3039b697c62', '1': 'bd6460b9-e046-4ad5-8760-6c89a187eba7'}\n"
     ]
    }
   ],
   "source": [
    "print(index.index_struct.nodes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'7e163de9-6172-497d-a1fd-dfbbb648b441': RefDocInfo(node_ids=['061539ee-ff3b-4113-a766-f3039b697c62', 'bd6460b9-e046-4ad5-8760-6c89a187eba7'], metadata={'file_path': 'docs\\\\问答手册.txt', 'file_name': 'e:/NLP/Python/try-rag/docs/问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2024-11-19', 'last_modified_date': '2024-11-19'})}\n"
     ]
    }
   ],
   "source": [
    "print(index.ref_doc_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='bd6460b9-e046-4ad5-8760-6c89a187eba7', embedding=None, metadata={'file_path': 'docs\\\\问答手册.txt', 'file_name': 'e:/NLP/Python/try-rag/docs/问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2024-11-19', 'last_modified_date': '2024-11-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='7e163de9-6172-497d-a1fd-dfbbb648b441', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'docs\\\\问答手册.txt', 'file_name': 'e:/NLP/Python/try-rag/docs/问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2024-11-19', 'last_modified_date': '2024-11-19'}, hash='a72c530c59da935d4a73b9d2e59a02d80f7618f736f9b52d75fbeab091523145'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='061539ee-ff3b-4113-a766-f3039b697c62', node_type=<ObjectType.TEXT: '1'>, metadata={'file_path': 'docs\\\\问答手册.txt', 'file_name': 'e:/NLP/Python/try-rag/docs/问答手册.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2024-11-19', 'last_modified_date': '2024-11-19'}, hash='9753ffda7b697335fd17f10798d641e4f23cd27b3013960ea0cd252c0b8d7a39')}, text='2) In the gaming industry, AI agents could transform the role of developers, shifting their focus from scripting non-player characters to refining agent learning processes. Similarly, adaptive robotic systems could redefine manufacturing roles, necessitating new skill sets rather than replacing human workers. Navigating these transitions responsibly is vital to minimize potential socio-economic disruptions.\\r\\n\\r\\nFurthermore, the agent AI focuses on learning collaboration policy in simulation and there is some risk if directly applying the policy to the real world due to the distribution shift. Robust testing and continual safety monitoring mechanisms should be put in place to minimize risks of unpredictable behaviors in real-world scenarios. Our “VideoAnalytica\" dataset is collected from the Internet and considering which is not a fully representative source, so we already go through-ed the ethical review and legal process from both Microsoft and University Washington. Be that as it may, we also need to understand biases that might exist in this corpus. Data distributions can be characterized in many ways. In this workshop, we have captured how the agent level distribution in our dataset is different from other existing datasets. However, there is much more than could be included in a single dataset or workshop. We would argue that there is a need for more approaches or discussion linked to real tasks or topics and that by making these data or system available.\\r\\n\\r\\nWe will dedicate a segment of our project to discussing these ethical issues, exploring potential mitigation strategies, and deploying a responsible multi-modal AI agent. We hope to help more researchers answer these questions together via this paper.', start_char_idx=1615, end_char_idx=3353, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.docstore.get_node('bd6460b9-e046-4ad5-8760-6c89a187eba7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.docstore.delete_document('bd6460b9-e046-4ad5-8760-6c89a187eba7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "transformations = [SentenceSplitter(chunk_size = 512)]\n",
    "\n",
    "from llama_index.core.ingestion.pipeline import run_transformations\n",
    "nodes = run_transformations(documents, transformations=transformations)\n",
    "index.insert_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "nodes = [\n",
    "    TextNode(\n",
    "        text=\"The Shawshank Redemption\",\n",
    "        metadata={\n",
    "            \"author\": \"Stephen King\",\n",
    "            \"theme\": \"Friendship\",\n",
    "            \"year\": 1994,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"The Godfather\",\n",
    "        metadata={\n",
    "            \"director\": \"Francis Ford Coppola\",\n",
    "            \"theme\": \"Mafia\",\n",
    "            \"year\": 1972,\n",
    "        },\n",
    "    )\n",
    "]\n",
    "index.insert_nodes(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造流式输出引擎\n",
    "query_engine = index.as_query_engine(\n",
    "    streaming=True, \n",
    "    similarity_top_k=3,\n",
    "    llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simpleNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting fastapi\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/54/c4/148d5046a96c428464557264877ae5a9338a83bbe0df045088749ec89820/fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
      "     ---------------------------------------- 94.9/94.9 KB 2.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from fastapi) (2.9.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from fastapi) (4.12.2)\n",
      "Collecting starlette<0.42.0,>=0.40.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/96/00/2b325970b3060c7cecebab6d295afe763365822b1306a12eeab198f74323/starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "     -------------------------------------- 73.2/73.2 KB 807.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.23.4)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from starlette<0.42.0,>=0.40.0->fastapi) (4.6.2.post1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.42.0,>=0.40.0->fastapi) (1.3.1)\n",
      "Installing collected packages: starlette, fastapi\n",
      "Successfully installed fastapi-0.115.5 starlette-0.41.3\n"
     ]
    }
   ],
   "source": [
    "%pip install fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting uvicorn\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/eb/14/78bd0e95dd2444b6caacbca2b730671d4295ccb628ef58b81bee903629df/uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
      "     -------------------------------------- 63.7/63.7 KB 490.7 kB/s eta 0:00:00\n",
      "Requirement already satisfied: click>=7.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from uvicorn) (8.1.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from uvicorn) (4.12.2)\n",
      "Requirement already satisfied: h11>=0.8 in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: colorama in e:\\nlp\\python\\try-rag\\rag\\lib\\site-packages (from click>=7.0->uvicorn) (0.4.6)\n",
      "Installing collected packages: uvicorn\n",
      "Successfully installed uvicorn-0.32.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个专注于学习和协作的人工智能助手。"
     ]
    }
   ],
   "source": [
    "response_stream = query_engine.query(\"你是谁？\") \n",
    "for text in response_stream.response_gen:\n",
    "    print(text,end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [8224]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:5000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:63947 - \"GET /stream_chat?param=%E4%BD%A0%E5%A5%BD HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [8224]\n"
     ]
    }
   ],
   "source": [
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from fastapi.responses import StreamingResponse\n",
    "app = FastAPI()\n",
    "app.add_middleware(CORSMiddleware,allow_origins=[\"*\"])\n",
    "@app.get('/stream_chat')\n",
    "async def stream_chat(param:str = \"你好\"):\n",
    "    async def generate():  \n",
    "        # 我们假设query_engine已经构建完成\n",
    "        response_stream = query_engine.query(param) \n",
    "        for text in response_stream.response_gen:\n",
    "            yield text\n",
    "    return StreamingResponse(generate(), media_type='text/event-stream')  \n",
    "if __name__ == '__main__':\n",
    "    #uvicorn.run(app, host='0.0.0.0', port=5000)\n",
    "    config = uvicorn.Config(app, host='0.0.0.0', port=5000)\n",
    "    server = uvicorn.Server(config)\n",
    "    await server.serve()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
